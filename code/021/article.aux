\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction to Transformers}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Transformer Architecture}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}What is attention}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}The Attention Mechanism}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}The General Attention Mechanism}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}The General Attention Mechanism with NumPy and SciPy}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}The Bahdanau Attention Mechanism}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Introduction to the Bahdanau Attention}{7}\protected@file@percent }
